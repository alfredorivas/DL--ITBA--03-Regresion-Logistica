{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Santander Customer Transaction Prediction (KAGGLE)\n",
    "\n",
    "Leer de que trata la competencia\n",
    "\n",
    "https://www.kaggle.com/c/santander-customer-transaction-prediction/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bajada de Dataset\n",
    "La siguiente celda baja el dataset y lo guarda en la carpeta /data.\n",
    "\n",
    "Luego de ejecutarla debería tener los archivos train.csv y test.csv en esta carpeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "if not os.path.isfile('data/train.csv'):\n",
    "    ! wget https://github.com/lab-pep-itba/santander-kaggle/blob/master/train.csv?raw=true\n",
    "    ! mv train.csv\\?raw\\=true data/train.csv\n",
    "if not os.path.isfile('data/test.csv'):\n",
    "    ! wget https://github.com/lab-pep-itba/santander-kaggle/blob/master/test.csv?raw=true\n",
    "    ! mv test.csv\\?raw\\=true data/test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar datos de test y de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "\n",
    "# TODO: Importar datos de test y asignarlos a la variable df_test desde la carpeta data/\n",
    "# df_test  = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Miramos las primeras 5 observaciones del dataset\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID_code', 'target', 'var_0', 'var_1', 'var_2', 'var_3', 'var_4',\n",
       "       'var_5', 'var_6', 'var_7',\n",
       "       ...\n",
       "       'var_190', 'var_191', 'var_192', 'var_193', 'var_194', 'var_195',\n",
       "       'var_196', 'var_197', 'var_198', 'var_199'],\n",
       "      dtype='object', length=202)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuantas features (covariables, variable explicativa, variable independiente, variables exógenas) hay (dimensión de las observaciones, regresoras)? Que columna contiene la salida (variable dependiente, variable endógena)? Cuantas clases hay? Cuantas observaciones tiene train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8  ...        var_190        var_191  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean       16.545850       0.284162  ...       3.234440       7.438408   \n",
       "std         3.418076       3.332634  ...       4.559922       3.023272   \n",
       "min         5.349700     -10.505500  ...     -14.093300      -2.691700   \n",
       "25%        13.943800      -2.317800  ...      -0.058825       5.157400   \n",
       "50%        16.456800       0.393700  ...       3.203600       7.347750   \n",
       "75%        19.102900       2.937900  ...       6.406200       9.512525   \n",
       "max        27.691800      10.151300  ...      18.440900      16.716500   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.927839       3.331774      17.993784      -0.142088   \n",
       "std         1.478423       3.992030       3.135162       1.429372   \n",
       "min        -3.814500     -11.783400       8.694400      -5.261000   \n",
       "25%         0.889775       0.584600      15.629800      -1.170700   \n",
       "50%         1.901300       3.396350      17.957950      -0.172700   \n",
       "75%         2.949500       6.205800      20.396525       0.829600   \n",
       "max         8.402400      18.281800      27.928800       4.272900   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
       "mean        2.303335       8.908158      15.870720      -3.326537  \n",
       "std         5.454369       0.921625       3.010945      10.438015  \n",
       "min       -14.209600       5.960600       6.299300     -38.852800  \n",
       "25%        -1.946925       8.252800      13.829700     -11.208475  \n",
       "50%         2.408900       8.888200      15.934050      -2.819550  \n",
       "75%         6.556725       9.593300      18.064725       4.836800  \n",
       "max        18.321500      12.000400      26.079100      28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Inspeccionar test\n",
    "# Puede ejecutar los métodos que crea necesarios. Recomendamos describe, columns, shape, head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que columna esta en los datos de train pero no en los de test? Cuantas observaciones de test hay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    179902\n",
       "1     20098\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que proporción de valores de 0s hay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89951"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "179902/(179902+20098)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Val, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['ID_code', 'target']).values[:160_000]\n",
    "X_val = df_train.drop(columns=['ID_code', 'target']).values[160_000:]\n",
    "y_train = df_train['target'].values[:160_000]\n",
    "y_val = df_train['target'].values[160_000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.77 s, sys: 152 ms, total: 8.92 s\n",
      "Wall time: 4.84 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julianganzabal/anaconda3/envs/mllab/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A que se debe el warning termino de converger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8507527588341866\n",
      "0.91206875\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_train, model.predict_proba(X_train)[:,1]))\n",
    "print(model.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8527383932243496\n",
      "0.912275\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_val, model.predict_proba(X_val)[:,1]))\n",
    "print(model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cuantos parámetros aprendio el modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = X_train.mean(axis=0)\n",
    "stds = X_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = (X_train - means)/stds\n",
    "X_val_normalized = (X_val - means)/stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 979 ms, sys: 110 ms, total: 1.09 s\n",
      "Wall time: 731 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000000000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = LogisticRegression(solver='lbfgs', C=1e12)\n",
    "%time model_2.fit(X_train_normalized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9144\n",
      "0.8606427374799213\n"
     ]
    }
   ],
   "source": [
    "print(model_2.score(X_train_normalized, y_train))\n",
    "print(roc_auc_score(y_train, model_2.predict_proba(X_train_normalized)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914525\n",
      "0.8629073823960288\n"
     ]
    }
   ],
   "source": [
    "print(model_2.score(X_val_normalized, y_val))\n",
    "print(roc_auc_score(y_val, model_2.predict_proba(X_val_normalized)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 81, 139,   6,  12,  53, 110,  76,  99, 146, 174,  26,  21,  22,\n",
       "        80, 190, 166, 165, 198,  13,  34, 169,  44,   2, 148,   0,  40,\n",
       "       133, 179, 170,  78,  94,   1, 184, 109,  33, 115,  92,  67, 149,\n",
       "       108, 191, 122, 173, 154,  18,  86, 192, 118, 107, 121, 147,  95,\n",
       "         9,  75,  35, 164, 177, 197, 172,  36, 127,  89, 123, 155,  91,\n",
       "       188,  56,  87,  71,  48,   5,  93, 162, 106, 157, 130, 141, 145,\n",
       "        24, 151,  32, 167, 163, 150, 186, 119,  49,  31, 180,  23, 111,\n",
       "       195,  90, 131, 125, 137, 114, 199,  43, 116, 135,  52,  58, 128,\n",
       "        70, 104, 175, 112, 132, 105,  11, 196,  85,  82, 194,  51,  28,\n",
       "       142,  83,  66, 134, 144, 138,  74,  45, 156,  77,  55,  97, 140,\n",
       "        20,  54, 193,  57,  88, 178,   8, 102, 113,  62,  15, 143, 159,\n",
       "       187, 181, 171,  63,  72,  64,  50,  59, 120, 168, 182, 101,  25,\n",
       "        68,   3,  65, 152,   4,  84,  37,  42, 176,  61, 129,  19, 189,\n",
       "        69,  47,  60,  16,  27,  29,  79,  73, 158,  96, 160,  46, 124,\n",
       "        98,  14, 153, 126,  39, 136, 183, 117,  41, 103, 100, 161,  10,\n",
       "         7, 185,  38,  17,  30])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(np.abs(model_2.coef_))[0][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = []\n",
    "for i in range(200):\n",
    "    correlations.append(np.corrcoef(y_train, X_train_normalized[:,i])[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 81, 139,  12, 110,   6,  26,  53, 146, 174,  76,  99,  80, 166,\n",
       "        22, 165,  21, 190, 148,   2,  13,  34, 133,   0, 198, 169, 109,\n",
       "       179,  44,  40,   1, 115, 149, 170, 184,  78,  94,  92, 108,  67,\n",
       "       191,  33,  18, 154, 173,  86, 122, 192, 147, 118,   9, 121,  75,\n",
       "        95, 164, 123,  35,  91,  36, 172, 127, 107, 155,  89, 177, 197,\n",
       "        56,  93, 188,  87,  71, 162,  48, 157, 106, 141, 145,   5,  32,\n",
       "       163, 131, 167, 186, 119,  49,  24, 151, 130,  90, 111, 135, 180,\n",
       "       125,  43,  51, 114, 195, 199,  52,  23, 150,  31, 116,  85,  70,\n",
       "       137, 105, 128, 104,  58, 112, 196, 132,  11,  28, 175,  66,  82,\n",
       "       194, 156,  83, 142,  45, 144,  88,  74, 178, 138,  77,   8,  97,\n",
       "       134,  20,  55, 193,  54,  15, 102,  57, 159, 140, 171,  62, 113,\n",
       "       187,  63, 143,  64,  25, 181,  50, 120, 168,  59,   3,  72,  65,\n",
       "        68,  84, 101,  19,   4,  37,  61,  69, 189, 152, 182,  42,  16,\n",
       "       129, 176,  47,  79, 153,  14, 183,  46, 160,  73,  60,  98, 158,\n",
       "       124,  27, 100,  96,  29,  39,  10, 117, 136,   7,  41, 103,  38,\n",
       "       161, 185,  30, 126,  17])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(np.abs(correlations))[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sq = X_train_normalized**2\n",
    "means_sq = X_train_sq.mean(axis=0)\n",
    "stds_sq = X_train_sq.std(axis=0)\n",
    "X_val_sq = X_val_normalized**2\n",
    "X_train_FE = np.append(X_train_normalized, (X_train_sq - means_sq)/stds_sq, axis=1)\n",
    "X_val_FE = np.append(X_val_normalized, (X_val_normalized**2-means_sq)/stds_sq, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.39 s, sys: 602 ms, total: 2.99 s\n",
      "Wall time: 2.31 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000000000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=1000,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = LogisticRegression(solver='lbfgs', C=1e12, max_iter=1000)\n",
    "%time model_3.fit(X_train_FE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9218625\n",
      "0.8910807733829336\n"
     ]
    }
   ],
   "source": [
    "print(model_3.score(X_train_FE, y_train))\n",
    "print(roc_auc_score(y_train, model_3.predict_proba(X_train_FE)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9221\n",
      "0.8927208344053872\n"
     ]
    }
   ],
   "source": [
    "print(model_3.score(X_val_FE, y_val))\n",
    "print(roc_auc_score(y_val, model_3.predict_proba(X_val_FE)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([139,  81,   6,  53,  12,  21,  76, 174, 110,  34, 146,  26, 169,\n",
       "        99, 165, 281,  22, 166, 190,  78,  33,  40,  13, 170, 149,  80,\n",
       "       148, 184,  94, 109, 133, 192,  92, 122, 115,  67, 121, 198,   0,\n",
       "         1, 173, 179,   2, 212,  18, 118, 108, 253, 398, 107, 191, 172,\n",
       "       177,  44, 154, 310, 164,  35, 197, 226, 188,  36, 339, 299,  75,\n",
       "       147, 244,   9, 280,  86,  87, 366,  95,  89,  48, 390, 127,  91,\n",
       "       222, 309,  71, 346, 155, 202,   5, 323, 374, 379,  56, 145, 106,\n",
       "       162, 123, 206, 221,  32, 186, 141, 200, 150, 348, 151,  31, 365,\n",
       "       199,  49, 130, 240,  23, 278, 167, 157,  24, 333,  90, 276,  93,\n",
       "       111, 119, 354, 137, 364, 195, 286, 363, 128, 112, 180, 380,  52,\n",
       "       104, 114,  58, 131,  70, 355, 116, 125, 135, 295, 370, 233, 391,\n",
       "       292, 201,  43, 275, 175, 196, 293, 357, 388, 294,  85, 163, 213,\n",
       "       347,  82, 308, 142, 132,  28, 105,  11, 319, 234, 194, 291,  74,\n",
       "       205,  97,  77, 140, 315,  45, 322,  20, 369,  55, 267, 256, 287,\n",
       "       156,  66, 289, 251, 144,  51,  54, 306, 332,  83, 377, 397, 321,\n",
       "       138, 134, 384, 330, 243, 218, 335,  57, 362, 341,   8,  88, 232,\n",
       "       345, 102, 314, 113, 178, 193, 372, 159, 307, 325, 209, 250, 331,\n",
       "       235, 373, 395, 367, 236, 311, 249, 396, 143, 288, 258, 252, 269,\n",
       "       187,  62, 318,  59, 327, 271,  64,  15, 368, 171, 349,  72, 312,\n",
       "       260,  63, 120, 350, 334, 211, 101,  50, 371, 375, 328, 168, 393,\n",
       "       394, 268,   4, 352, 262, 338, 351,  65,  84, 344, 181, 176, 228,\n",
       "       386, 283, 272, 343, 216, 337, 387,  42, 152, 282, 215, 189, 182,\n",
       "         3, 270, 248,  37, 219,  25, 305,  68,  19, 353, 290, 129, 279,\n",
       "       381, 285,  61, 378, 302, 298, 297, 263, 336, 203, 266, 246, 223,\n",
       "       356, 277, 316, 239, 342, 241,  69, 208, 204,  29, 304, 392,  47,\n",
       "        96, 301, 225, 383, 399, 313, 255, 153, 259, 324, 326, 160, 265,\n",
       "       238, 245, 158, 261, 224,  16, 136,  39, 126,  41,  27, 376, 329,\n",
       "        73,  60, 242, 317, 227, 124,  46,  79, 360,  14, 183, 257,  98,\n",
       "       229, 303, 237, 296, 264, 274, 103, 273, 359, 320, 210, 361, 300,\n",
       "       185, 389, 385, 247, 214, 284, 161, 217, 358, 207, 100, 340, 220,\n",
       "        38, 382, 230,  17, 231,   7,  10, 117, 254,  30])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(np.abs(model_3.coef_))[0][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([139,  81,   6,  53,  12,  21,  76, 174, 110,  34, 146,  26, 169,\n",
       "        99, 165, 281,  22, 166, 190,  78,  33,  40,  13, 170, 149,  80,\n",
       "       148, 184,  94, 109, 133, 192,  92, 115, 122,  67, 121, 198,   0,\n",
       "         1, 173, 179,   2, 212,  18, 118, 108, 253, 107, 398, 191, 172,\n",
       "       177,  44, 154, 310, 164,  35, 197, 226, 188,  36, 339, 299,  75,\n",
       "       147, 244,   9, 280,  86,  87, 366,  95,  89,  48, 127, 390,  91,\n",
       "       222, 309,  71, 346, 155, 202,   5, 323, 374, 379,  56, 145, 106,\n",
       "       162, 123, 206, 221,  32, 186, 141, 200, 150, 348, 151,  31, 365,\n",
       "        49, 199, 130, 240,  23, 167, 278, 157,  24, 333,  90, 276, 111,\n",
       "        93, 119, 354, 137, 364, 195, 286, 363, 128, 112, 180, 380,  52,\n",
       "       104, 114, 131,  58,  70, 355, 116, 125, 135, 295, 370, 233, 391,\n",
       "       292, 201,  43, 275, 196, 175, 293, 357, 388, 294, 163,  85, 213,\n",
       "       347,  82, 308, 142, 132,  28, 105,  11, 319, 234, 194, 291,  74,\n",
       "       205,  97,  77, 140,  45, 315, 322,  20, 369,  55, 267, 256, 287,\n",
       "       156,  66, 289, 251, 144,  51,  54, 306, 332,  83, 377, 397, 321,\n",
       "       138, 134, 384, 330, 243, 218, 335,  57, 362, 341,   8,  88, 232,\n",
       "       345, 102, 113, 314, 193, 178, 372, 159, 307, 325, 209, 250, 331,\n",
       "       235, 373, 395, 367, 236, 311, 249, 396, 143, 288, 258, 252, 269,\n",
       "       187,  62, 318,  59, 327, 271,  64,  15, 368, 171, 349,  72, 312,\n",
       "       260,  63, 120, 350, 334, 211, 101,  50, 371, 375, 328, 168, 393,\n",
       "       394, 268,   4, 352, 262, 338, 351,  84,  65, 344, 181, 176, 228,\n",
       "       386, 283, 272, 343, 216, 337, 387,  42, 152, 282, 215, 189, 182,\n",
       "         3, 270, 248,  37, 219,  25, 305,  68,  19, 353, 290, 129, 279,\n",
       "       381, 285,  61, 378, 302, 298, 297, 263, 336, 203, 266, 246, 223,\n",
       "       356, 277, 316, 239, 342, 241,  69, 208, 204,  29, 304, 392,  47,\n",
       "        96, 301, 225, 383, 399, 313, 153, 255, 259, 324, 326, 160, 265,\n",
       "       238, 245, 158, 261, 224,  16, 136,  39, 126,  41,  27, 376, 329,\n",
       "        73,  60, 242, 317, 227, 124,  46,  79, 360,  14, 183,  98, 257,\n",
       "       229, 303, 237, 296, 264, 274, 103, 273, 359, 320, 210, 361, 300,\n",
       "       185, 389, 385, 247, 214, 284, 161, 217, 207, 358, 100, 340, 220,\n",
       "        38, 382,  17, 230, 231,   7,  10, 117, 254,  30])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(np.abs(model_3.coef_)*X_train_FE.std(axis=0))[0][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
